{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aflokkat-ia/anaconda3/envs/tuto_langchain_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/aflokkat-ia/anaconda3/envs/tuto_langchain_env/lib/python3.12/site-packages/langchain_mistralai/embeddings.py:180: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_mistralai import MistralAIEmbeddings, ChatMistralAI\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"MISTRAL_API_KEY\"):\n",
    "  os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\n",
    "      \"Enter API key for Mistral AI: \")\n",
    "\n",
    "\n",
    "llm = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "\n",
    "\n",
    "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/home/aflokkat-ia/anaconda3/envs/tuto_langchain_env/lib/python3.12/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke(\n",
    "        {\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aflokkat-ia/anaconda3/envs/tuto_langchain_env/lib/python3.12/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=cc31a19f-a23d-43f6-9c3b-43d71133bd79; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=4e50fb2b-66fe-48c9-8291-29fa5bab2397; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=9ff20909-b9f1-4fd2-bd22-cbbfcc10be0f; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=79b28c83-534e-4ac3-9b32-82ca021a4940\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=c5d4b1a0-fc5a-4143-8d7c-10e4d4aa255e; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=0b04f164-d696-4b30-ba15-457550ac231f; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=9b6a4299-95e7-4df9-9b08-5e34d8b1ff39; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=a2275630-8e0d-40eb-a805-e6c90a15ca7e; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=79b28c83-534e-4ac3-9b32-82ca021a4940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition is a strategy where a complex task is broken down into smaller, more manageable steps. This can be achieved through methods like Chain of Thought prompting, where a model is instructed to \"think step by step,\" or through more structured approaches like Tree of Thoughts, which explores multiple reasoning paths. It can be done by large language models with prompting, using task-specific instructions, or with human inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=270b83a8-f0ed-4a69-9c51-851a06d922cf; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=0b04f164-d696-4b30-ba15-457550ac231f; trace=7c777dfd-e6ed-4e95-81ba-3f6b3e868a61,id=a2275630-8e0d-40eb-a805-e6c90a15ca7e\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"./data/Plan_type_mémoire_d_étude.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAN TYPE D’UN RAPPORT DE MISSION DE FIN D’ETUDES \n",
      "EN MASTER OF SCIENCE BIHAR \n",
      "Vous trouverez ci -dessous le plan type d ’un rapport de  mission de fin d ’études ( MFE) en \n",
      "entreprise, pour un projet \n",
      "\n",
      "{'source': './data/Plan_type_mémoire_d_étude.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{docs[0].page_content[:200]}\\n\")\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuto_langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
